nohup: ignoring input
Not matched: ../datasets/data/train/dialogues_096.json | SSNG0201.json | hotel | hotel-name | hobsons house
Not matched: ../datasets/data/train/dialogues_097.json | MUL0152.json | taxi | taxi-departure | a and b guest house
Not matched: ../datasets/data/train/dialogues_097.json | MUL0152.json | hotel | hotel-name | a and b guest house
Not matched: ../datasets/data/train/dialogues_105.json | PMUL3484.json | taxi | taxi-departure | aylesbray lodge guest house
Not matched: ../datasets/data/train/dialogues_105.json | SNG01373.json | taxi | taxi-arriveby | one o'clock p.m
Not matched: ../datasets/data/train/dialogues_106.json | PMUL1303.json | bus | bus-departure | cambridge
Not matched: ../datasets/data/train/dialogues_107.json | SNG01631.json | taxi | taxi-arriveby | ten o'clock a.m
Not matched: ../datasets/data/train/dialogues_108.json | WOZ20245.json | restaurant | restaurant-name | pizza hut cherry hinton
Not matched: ../datasets/data/train/dialogues_108.json | SSNG0367.json | hotel | hotel-name | a and b guest house
Not matched: ../datasets/data/train/dialogues_112.json | SSNG0338.json | hotel | hotel-name | gonville hotel
Not matched: ../datasets/data/train/dialogues_115.json | SNG01929.json | taxi | taxi-arriveby | three forty five p.m
Not matched: ../datasets/data/train/dialogues_122.json | PMUL0192.json | hotel | hotel-name | rosas bed and breakfast
Not matched: ../datasets/data/train/dialogues_124.json | MUL1356.json | taxi | taxi-departure | university arms hotel
Not matched: ../datasets/data/train/dialogues_124.json | MUL1356.json | hotel | hotel-name | university arms hotel
Not matched: ../datasets/data/train/dialogues_134.json | PMUL0208.json | hotel | hotel-name | worth house
Not matched: ../datasets/data/train/dialogues_136.json | SSNG0348.json | hotel | hotel-name | archway house
Not matched: ../datasets/data/train/dialogues_137.json | MUL0120.json | taxi | taxi-destination | efes restaurant
0.43558998180798847
Not matched: ../datasets/data/dev/dialogues_015.json | PMUL3979.json | taxi | taxi-destination | cambridge
Not matched: ../datasets/data/dev/dialogues_017.json | SNG01172.json | restaurant | restaurant-name | efes restaurant
0.4255997449589543
06/23/2021 03:18:44 - INFO - __main__ -    Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Use FP16 precision: False

loading configuration file https://huggingface.co/xlnet-large-cased/resolve/main/config.json from cache at /dhome/boewoei0123/.cache/huggingface/transformers/1f0d5fc4143aa8fe332810bac98d442fed5483549adcd9656e5709cd470003a0.a0945cddd1ef8f9d9c40c35c36bad4908625533057baeeafc6d26a9550f18c60
Model config XLNetConfig {
  "architectures": [
    "XLNetLMHeadModel"
  ],
  "attn_type": "bi",
  "bi_data": false,
  "bos_token_id": 1,
  "clamp_len": -1,
  "d_head": 64,
  "d_inner": 4096,
  "d_model": 1024,
  "dropout": 0.1,
  "end_n_top": 5,
  "eos_token_id": 2,
  "ff_activation": "gelu",
  "initializer_range": 0.02,
  "layer_norm_eps": 1e-12,
  "mem_len": null,
  "model_type": "xlnet",
  "n_head": 16,
  "n_layer": 24,
  "pad_token_id": 5,
  "reuse_len": null,
  "same_length": false,
  "start_n_top": 5,
  "summary_activation": "tanh",
  "summary_last_dropout": 0.1,
  "summary_type": "last",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 250
    }
  },
  "transformers_version": "4.6.0",
  "untie_r": true,
  "use_mems_eval": true,
  "use_mems_train": false,
  "vocab_size": 32000
}

loading file https://huggingface.co/xlnet-large-cased/resolve/main/spiece.model from cache at /dhome/boewoei0123/.cache/huggingface/transformers/3af982b422f8bb8c510fdd1112afe6f5ec3f3219ef859edcf4c3826bec14832e.d93497120e3a865e2970f26abdf7bf375896f97fde8b874b70909592a6c785c9
loading file https://huggingface.co/xlnet-large-cased/resolve/main/tokenizer.json from cache at /dhome/boewoei0123/.cache/huggingface/transformers/6a4afd4829edeea0c7fe7735eccea233e66e79729e574966cfd9ec47f81d269a.2a683f915238b4f560dab0c724066cf0a7de9a851e96b0fb3a1e7f0881552f53
loading file https://huggingface.co/xlnet-large-cased/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/xlnet-large-cased/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/xlnet-large-cased/resolve/main/tokenizer_config.json from cache at None
06/23/2021 03:18:49 - INFO - __main__ -    Saving tokenizer to ./saved/0623-0318/tokenizer...
tokenizer config file saved in ./saved/0623-0318/tokenizer_config.json
Special tokens file saved in ./saved/0623-0318/special_tokens_map.json
loading weights file https://huggingface.co/xlnet-large-cased/resolve/main/pytorch_model.bin from cache at /dhome/boewoei0123/.cache/huggingface/transformers/0c2b00a768ca7c5b3534b75606a47a7e1125b10ce354b217022de5a12029859c.7fff7afe180c24f31dabdb196f95ca2e26a8aa357c1db6137f4fec6430db9776
Some weights of the model checkpoint at xlnet-large-cased were not used when initializing XLNetForQuestionAnswering: ['lm_loss.weight', 'lm_loss.bias']
- This IS expected if you are initializing XLNetForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLNetForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLNetForQuestionAnswering were not initialized from the model checkpoint at xlnet-large-cased and are newly initialized: ['answer_class.dense_1.weight', 'answer_class.dense_0.bias', 'end_logits.dense_1.bias', 'end_logits.LayerNorm.weight', 'end_logits.dense_1.weight', 'start_logits.dense.bias', 'start_logits.dense.weight', 'end_logits.LayerNorm.bias', 'end_logits.dense_0.weight', 'answer_class.dense_0.weight', 'end_logits.dense_0.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
06/23/2021 03:18:56 - WARNING - datasets.builder -    Using custom data configuration default-b76343d9c1272ce5
0 tables [00:00, ? tables/s]1 tables [00:00,  2.33 tables/s]                                0 tables [00:00, ? tables/s]                            Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /dhome/boewoei0123/.cache/huggingface/datasets/json/default-b76343d9c1272ce5/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02...
Dataset json downloaded and prepared to /dhome/boewoei0123/.cache/huggingface/datasets/json/default-b76343d9c1272ce5/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02. Subsequent calls will reuse this data.
 #0:   0%|          | 0/44 [00:00<?, ?ba/s]

 #2:   0%|          | 0/44 [00:00<?, ?ba/s][A[A
 #1:   0%|          | 0/44 [00:00<?, ?ba/s][A


 #3:   0%|          | 0/44 [00:00<?, ?ba/s][A[A[A
 #1:   2%|â–         | 1/44 [00:00<00:39,  1.08ba/s][A #0:   2%|â–         | 1/44 [00:01<00:46,  1.08s/ba]

 #2:   2%|â–         | 1/44 [00:01<00:45,  1.05s/ba][A[A


 #3:   2%|â–         | 1/44 [00:01<00:48,  1.12s/ba][A[A[A
 #1:   5%|â–         | 2/44 [00:01<00:40,  1.03ba/s][A #0:   5%|â–         | 2/44 [00:02<00:47,  1.12s/ba]


 #3:   5%|â–         | 2/44 [00:02<00:47,  1.13s/ba][A[A[A

 #2:   5%|â–         | 2/44 [00:02<00:46,  1.12s/ba][A[A
 #1:   7%|â–‹         | 3/44 [00:03<00:41,  1.01s/ba][A #0:   7%|â–‹         | 3/44 [00:03<00:46,  1.13s/ba]


 #3:   7%|â–‹         | 3/44 [00:03<00:46,  1.13s/ba][A[A[A

 #2:   7%|â–‹         | 3/44 [00:03<00:46,  1.13s/ba][A[A
 #1:   9%|â–‰         | 4/44 [00:04<00:40,  1.02s/ba][A #0:   9%|â–‰         | 4/44 [00:04<00:43,  1.08s/ba]


 #3:   9%|â–‰         | 4/44 [00:04<00:46,  1.16s/ba][A[A[A

 #2:   9%|â–‰         | 4/44 [00:04<00:47,  1.19s/ba][A[A #0:  11%|â–ˆâ–        | 5/44 [00:05<00:40,  1.03s/ba]
 #1:  11%|â–ˆâ–        | 5/44 [00:05<00:42,  1.08s/ba][A


 #3:  11%|â–ˆâ–        | 5/44 [00:05<00:44,  1.13s/ba][A[A[A

 #2:  11%|â–ˆâ–        | 5/44 [00:06<00:46,  1.19s/ba][A[A #0:  14%|â–ˆâ–Ž        | 6/44 [00:06<00:40,  1.08s/ba]
 #1:  14%|â–ˆâ–Ž        | 6/44 [00:06<00:42,  1.13s/ba][A


 #3:  14%|â–ˆâ–Ž        | 6/44 [00:06<00:42,  1.11s/ba][A[A[A

 #2:  14%|â–ˆâ–Ž        | 6/44 [00:07<00:43,  1.14s/ba][A[A #0:  16%|â–ˆâ–Œ        | 7/44 [00:07<00:42,  1.14s/ba]


 #3:  16%|â–ˆâ–Œ        | 7/44 [00:07<00:41,  1.13s/ba][A[A[A

 #2:  16%|â–ˆâ–Œ        | 7/44 [00:08<00:41,  1.13s/ba][A[A
 #1:  16%|â–ˆâ–Œ        | 7/44 [00:08<00:47,  1.29s/ba][A #0:  18%|â–ˆâ–Š        | 8/44 [00:08<00:40,  1.12s/ba]


 #3:  18%|â–ˆâ–Š        | 8/44 [00:08<00:39,  1.10s/ba][A[A[A

 #2:  18%|â–ˆâ–Š        | 8/44 [00:09<00:41,  1.14s/ba][A[A #0:  20%|â–ˆâ–ˆ        | 9/44 [00:10<00:39,  1.13s/ba]
 #1:  18%|â–ˆâ–Š        | 8/44 [00:10<00:52,  1.45s/ba][A


 #3:  20%|â–ˆâ–ˆ        | 9/44 [00:10<00:39,  1.12s/ba][A[A[A

 #2:  20%|â–ˆâ–ˆ        | 9/44 [00:10<00:43,  1.23s/ba][A[A


 #3:  23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:11<00:38,  1.14s/ba][A[A[A #0:  23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:11<00:40,  1.20s/ba]
 #1:  20%|â–ˆâ–ˆ        | 9/44 [00:11<00:52,  1.51s/ba][A

 #2:  23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:12<00:43,  1.28s/ba][A[A


 #3:  25%|â–ˆâ–ˆâ–Œ       | 11/44 [00:12<00:37,  1.13s/ba][A[A[A #0:  25%|â–ˆâ–ˆâ–Œ       | 11/44 [00:12<00:41,  1.25s/ba]
 #1:  23%|â–ˆâ–ˆâ–Ž       | 10/44 [00:12<00:47,  1.40s/ba][A

 #2:  25%|â–ˆâ–ˆâ–Œ       | 11/44 [00:13<00:39,  1.21s/ba][A[A


 #3:  27%|â–ˆâ–ˆâ–‹       | 12/44 [00:13<00:36,  1.13s/ba][A[A[A #0:  27%|â–ˆâ–ˆâ–‹       | 12/44 [00:13<00:39,  1.22s/ba]
 #1:  25%|â–ˆâ–ˆâ–Œ       | 11/44 [00:14<00:44,  1.33s/ba][A

 #2:  27%|â–ˆâ–ˆâ–‹       | 12/44 [00:14<00:36,  1.14s/ba][A[A


 #3:  30%|â–ˆâ–ˆâ–‰       | 13/44 [00:14<00:35,  1.13s/ba][A[A[A #0:  30%|â–ˆâ–ˆâ–‰       | 13/44 [00:15<00:37,  1.20s/ba]
 #1:  27%|â–ˆâ–ˆâ–‹       | 12/44 [00:15<00:39,  1.25s/ba][A

 #2:  30%|â–ˆâ–ˆâ–‰       | 13/44 [00:15<00:36,  1.19s/ba][A[A


 #3:  32%|â–ˆâ–ˆâ–ˆâ–      | 14/44 [00:15<00:34,  1.14s/ba][A[A[A
 #1:  30%|â–ˆâ–ˆâ–‰       | 13/44 [00:16<00:37,  1.21s/ba][A #0:  32%|â–ˆâ–ˆâ–ˆâ–      | 14/44 [00:16<00:36,  1.21s/ba]

 #2:  32%|â–ˆâ–ˆâ–ˆâ–      | 14/44 [00:16<00:38,  1.27s/ba][A[A


 #3:  34%|â–ˆâ–ˆâ–ˆâ–      | 15/44 [00:16<00:32,  1.12s/ba][A[A[A
 #1:  32%|â–ˆâ–ˆâ–ˆâ–      | 14/44 [00:17<00:35,  1.18s/ba][A #0:  34%|â–ˆâ–ˆâ–ˆâ–      | 15/44 [00:17<00:37,  1.29s/ba]


 #3:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 16/44 [00:18<00:31,  1.12s/ba][A[A[A

 #2:  34%|â–ˆâ–ˆâ–ˆâ–      | 15/44 [00:18<00:36,  1.27s/ba][A[A
 #1:  34%|â–ˆâ–ˆâ–ˆâ–      | 15/44 [00:18<00:33,  1.16s/ba][A


 #3:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 17/44 [00:19<00:29,  1.11s/ba][A[A[A #0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 16/44 [00:19<00:37,  1.34s/ba]
 #1:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 16/44 [00:19<00:33,  1.19s/ba][A

 #2:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 16/44 [00:19<00:37,  1.35s/ba][A[A


 #3:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/44 [00:20<00:28,  1.10s/ba][A[A[A #0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 17/44 [00:20<00:35,  1.32s/ba]
 #1:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 17/44 [00:21<00:33,  1.24s/ba][A

 #2:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 17/44 [00:21<00:37,  1.38s/ba][A[A


 #3:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 19/44 [00:21<00:27,  1.08s/ba][A[A[A #0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/44 [00:21<00:34,  1.31s/ba]


 #3:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [00:22<00:25,  1.07s/ba][A[A[A

 #2:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/44 [00:22<00:36,  1.40s/ba][A[A
 #1:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/44 [00:22<00:34,  1.34s/ba][A #0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 19/44 [00:22<00:30,  1.24s/ba]


 #3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 21/44 [00:23<00:25,  1.10s/ba][A[A[A
 #1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 19/44 [00:23<00:30,  1.23s/ba][A

 #2:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 19/44 [00:23<00:34,  1.37s/ba][A[A #0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [00:24<00:29,  1.22s/ba]


 #3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22/44 [00:24<00:23,  1.09s/ba][A[A[A

 #2:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [00:24<00:30,  1.25s/ba][A[A
 #1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [00:24<00:30,  1.25s/ba][A #0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 21/44 [00:25<00:29,  1.29s/ba]


 #3:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/44 [00:25<00:23,  1.10s/ba][A[A[A

 #2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 21/44 [00:26<00:28,  1.25s/ba][A[A
 #1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 21/44 [00:26<00:29,  1.27s/ba][A #0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22/44 [00:26<00:27,  1.24s/ba]


 #3:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/44 [00:26<00:22,  1.11s/ba][A[A[A
 #1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22/44 [00:27<00:26,  1.22s/ba][A

 #2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22/44 [00:27<00:28,  1.28s/ba][A[A #0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/44 [00:27<00:24,  1.19s/ba]


 #3:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 25/44 [00:27<00:21,  1.11s/ba][A[A[A

 #2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/44 [00:28<00:27,  1.32s/ba][A[A
 #1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/44 [00:28<00:27,  1.33s/ba][A


 #3:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 26/44 [00:29<00:20,  1.13s/ba][A[A[A #0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/44 [00:29<00:26,  1.31s/ba]

 #2:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/44 [00:29<00:24,  1.24s/ba][A[A


 #3:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/44 [00:30<00:18,  1.11s/ba][A[A[A
 #1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/44 [00:30<00:26,  1.32s/ba][A #0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 25/44 [00:30<00:24,  1.28s/ba]


 #3:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 28/44 [00:31<00:18,  1.13s/ba][A[A[A #0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 26/44 [00:31<00:22,  1.23s/ba]
 #1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 25/44 [00:31<00:25,  1.33s/ba][A

 #2:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 25/44 [00:31<00:27,  1.44s/ba][A[A


 #3:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 29/44 [00:32<00:17,  1.13s/ba][A[A[A #0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/44 [00:32<00:20,  1.19s/ba]
 #1:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 26/44 [00:32<00:22,  1.27s/ba][A

 #2:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 26/44 [00:33<00:26,  1.48s/ba][A[A


 #3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [00:33<00:15,  1.14s/ba][A[A[A
 #1:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/44 [00:33<00:20,  1.18s/ba][A #0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 28/44 [00:33<00:18,  1.18s/ba]
 #1:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 28/44 [00:34<00:18,  1.13s/ba][A

 #2:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 27/44 [00:34<00:24,  1.42s/ba][A[A


 #3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 31/44 [00:34<00:14,  1.14s/ba][A[A[A #0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 29/44 [00:35<00:18,  1.23s/ba]
 #1:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 29/44 [00:35<00:16,  1.10s/ba][A


 #3:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 32/44 [00:35<00:13,  1.10s/ba][A[A[A

 #2:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 28/44 [00:35<00:21,  1.33s/ba][A[A


 #3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 33/44 [00:36<00:12,  1.11s/ba][A[A[A

 #2:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 29/44 [00:37<00:19,  1.29s/ba][A[A #0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [00:37<00:20,  1.43s/ba]
 #1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [00:37<00:17,  1.23s/ba][A


 #3:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 34/44 [00:37<00:10,  1.08s/ba][A[A[A #0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 31/44 [00:38<00:17,  1.37s/ba]

 #2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [00:38<00:18,  1.31s/ba][A[A


 #3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 35/44 [00:38<00:09,  1.07s/ba][A[A[A
 #1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 31/44 [00:39<00:18,  1.40s/ba][A #0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 32/44 [00:39<00:15,  1.29s/ba]

 #2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 31/44 [00:39<00:16,  1.29s/ba][A[A


 #3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 36/44 [00:40<00:08,  1.10s/ba][A[A[A #0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 33/44 [00:40<00:14,  1.31s/ba]
 #1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 32/44 [00:40<00:18,  1.54s/ba][A

 #2:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 32/44 [00:41<00:15,  1.32s/ba][A[A


 #3:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/44 [00:41<00:07,  1.09s/ba][A[A[A #0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 34/44 [00:41<00:12,  1.26s/ba]

 #2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 33/44 [00:42<00:14,  1.28s/ba][A[A


 #3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 38/44 [00:42<00:06,  1.09s/ba][A[A[A
 #1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 33/44 [00:42<00:18,  1.64s/ba][A #0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 35/44 [00:42<00:10,  1.18s/ba]

 #2:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 34/44 [00:43<00:12,  1.21s/ba][A[A


 #3:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 39/44 [00:43<00:05,  1.12s/ba][A[A[A
 #1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 34/44 [00:44<00:15,  1.58s/ba][A #0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 36/44 [00:44<00:09,  1.24s/ba]

 #2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 35/44 [00:44<00:10,  1.17s/ba][A[A


 #3:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [00:44<00:04,  1.15s/ba][A[A[A
 #1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 35/44 [00:45<00:13,  1.46s/ba][A #0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/44 [00:45<00:08,  1.22s/ba]

 #2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 36/44 [00:45<00:09,  1.21s/ba][A[A


 #3:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 41/44 [00:45<00:03,  1.15s/ba][A[A[A #0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 38/44 [00:46<00:07,  1.20s/ba]


 #3:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 42/44 [00:46<00:02,  1.13s/ba][A[A[A
 #1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 36/44 [00:47<00:12,  1.54s/ba][A

 #2:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/44 [00:47<00:09,  1.31s/ba][A[A


 #3:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 43/44 [00:48<00:01,  1.15s/ba][A[A[A #0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 39/44 [00:48<00:06,  1.36s/ba]

 #2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 38/44 [00:48<00:08,  1.34s/ba][A[A
 #1:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/44 [00:48<00:10,  1.54s/ba][A


 #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:48<00:00,  1.03s/ba][A[A[A #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:48<00:00,  1.11s/ba]

 #2:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 39/44 [00:50<00:06,  1.36s/ba][A[A
 #1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 38/44 [00:50<00:08,  1.48s/ba][A #0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [00:50<00:06,  1.52s/ba]

 #2:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [00:51<00:05,  1.36s/ba][A[A #0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 41/44 [00:51<00:04,  1.49s/ba]
 #1:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 39/44 [00:51<00:07,  1.56s/ba][A

 #2:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 41/44 [00:52<00:04,  1.34s/ba][A[A #0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 42/44 [00:52<00:02,  1.43s/ba]
 #1:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [00:53<00:06,  1.58s/ba][A #0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 43/44 [00:54<00:01,  1.32s/ba]

 #2:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 42/44 [00:54<00:02,  1.35s/ba][A[A
 #1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 41/44 [00:54<00:04,  1.45s/ba][A #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:54<00:00,  1.17s/ba] #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:54<00:00,  1.25s/ba]

 #2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 43/44 [00:55<00:01,  1.33s/ba][A[A
 #1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 42/44 [00:55<00:02,  1.32s/ba][A

 #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:56<00:00,  1.25s/ba][A[A #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:56<00:00,  1.28s/ba]
 #1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 43/44 [00:56<00:01,  1.18s/ba][A
 #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:57<00:00,  1.03s/ba][A #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44/44 [00:57<00:00,  1.30s/ba]

 #0:   0%|          | 0/7 [00:00<?, ?ba/s]
 #1:   0%|          | 0/7 [00:00<?, ?ba/s][A

 #2:   0%|          | 0/7 [00:00<?, ?ba/s][A[A


 #3:   0%|          | 0/7 [00:00<?, ?ba/s][A[A[A #0:  14%|â–ˆâ–        | 1/7 [00:02<00:12,  2.10s/ba]

 #2:  14%|â–ˆâ–        | 1/7 [00:02<00:12,  2.14s/ba][A[A


 #3:  14%|â–ˆâ–        | 1/7 [00:02<00:14,  2.49s/ba][A[A[A
 #1:  14%|â–ˆâ–        | 1/7 [00:03<00:18,  3.09s/ba][A #0:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:04<00:10,  2.16s/ba]


 #3:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:04<00:12,  2.44s/ba][A[A[A

 #2:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:04<00:11,  2.31s/ba][A[A
 #1:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:04<00:13,  2.73s/ba][A #0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:06<00:08,  2.13s/ba]

 #2:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:06<00:09,  2.25s/ba][A[A


 #3:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:07<00:09,  2.43s/ba][A[A[A
 #1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:07<00:10,  2.65s/ba][A #0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:08<00:06,  2.12s/ba]

 #2:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:09<00:07,  2.35s/ba][A[A


 #3:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:09<00:07,  2.39s/ba][A[A[A
 #1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:09<00:07,  2.56s/ba][A #0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:11<00:04,  2.44s/ba]


 #3:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:11<00:04,  2.40s/ba][A[A[A
 #1:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:12<00:04,  2.46s/ba][A

 #2:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:12<00:04,  2.41s/ba][A[A #0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:14<00:02,  2.46s/ba]


 #3:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:14<00:02,  2.37s/ba][A[A[A

 #2:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:14<00:02,  2.38s/ba][A[A #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  1.91s/ba] #0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  2.12s/ba]


 #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  1.84s/ba][A[A[A #3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  2.12s/ba]

 #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  1.83s/ba][A[A #2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  2.14s/ba]
 #1:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:15<00:02,  2.70s/ba][A
 #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:15<00:00,  2.06s/ba][A #1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:15<00:00,  2.27s/ba]


06/23/2021 03:20:15 - INFO - __main__ -    
******** Running training ********
06/23/2021 03:20:15 - INFO - __main__ -    Num train examples = 188150
06/23/2021 03:20:15 - INFO - __main__ -    Num Epochs = 3
06/23/2021 03:20:15 - INFO - __main__ -    Instantaneous batch size per device = 4
06/23/2021 03:20:15 - INFO - __main__ -    Total train batch size (w/ parallel, distributed & accumulation) = 64
06/23/2021 03:20:15 - INFO - __main__ -    Instantaneous steps per epoch = 47038
06/23/2021 03:20:15 - INFO - __main__ -    Update steps per epoch = 2940
06/23/2021 03:20:15 - INFO - __main__ -    Total update steps = 8820
06/23/2021 03:20:15 - INFO - __main__ -    
Epoch 01 / 03
06/23/2021 03:29:18 - INFO - __main__ -    Train | Loss: 6.59207
06/23/2021 03:38:19 - INFO - __main__ -    Train | Loss: 5.36132
06/23/2021 03:47:20 - INFO - __main__ -    Train | Loss: 4.33942
06/23/2021 03:56:21 - INFO - __main__ -    Train | Loss: 3.62961
06/23/2021 04:05:22 - INFO - __main__ -    Train | Loss: 3.05488
06/23/2021 04:14:24 - INFO - __main__ -    Train | Loss: 2.63341
06/23/2021 04:22:42 - INFO - __main__ -    Train | Loss: 2.31786
06/23/2021 04:30:27 - INFO - __main__ -    Train | Loss: 2.07145
06/23/2021 04:38:10 - INFO - __main__ -    Train | Loss: 1.87547
06/23/2021 04:45:53 - INFO - __main__ -    Train | Loss: 1.71647
06/23/2021 04:53:37 - INFO - __main__ -    Train | Loss: 1.58229
06/23/2021 05:01:19 - INFO - __main__ -    Train | Loss: 1.47093
06/23/2021 05:09:02 - INFO - __main__ -    Train | Loss: 1.37317
06/23/2021 05:16:46 - INFO - __main__ -    Train | Loss: 1.28916
06/23/2021 05:24:30 - INFO - __main__ -    Train | Loss: 1.21593
06/23/2021 05:32:13 - INFO - __main__ -    Train | Loss: 1.15113
06/23/2021 05:39:57 - INFO - __main__ -    Train | Loss: 1.09268
06/23/2021 05:47:39 - INFO - __main__ -    Train | Loss: 1.04001
06/23/2021 05:55:20 - INFO - __main__ -    Train | Loss: 0.99264
06/23/2021 06:03:01 - INFO - __main__ -    Train | Loss: 0.94959
06/23/2021 06:10:43 - INFO - __main__ -    Train | Loss: 0.91111
06/23/2021 06:18:24 - INFO - __main__ -    Train | Loss: 0.87516
06/23/2021 06:26:08 - INFO - __main__ -    Train | Loss: 0.84212
06/23/2021 06:33:52 - INFO - __main__ -    Train | Loss: 0.81237
06/23/2021 06:41:35 - INFO - __main__ -    Train | Loss: 0.78418
06/23/2021 07:13:09 - INFO - pred_utils -    Post-processing 25094 example predictions split into 26864 features.
06/23/2021 07:14:50 - INFO - __main__ -    Valid | MAA: 0.97569, JAA: 0.80497, MEM: 0.93652, JEM: 0.77362, MGA: 0.95517, JGA: 0.65635
Configuration saved in ./saved/0623-0318/config.json
Model weights saved in ./saved/0623-0318/pytorch_model.bin
06/23/2021 07:14:52 - INFO - __main__ -    Saving config and model to ./saved/0623-0318...
06/23/2021 07:22:33 - INFO - __main__ -    Train | Loss: 0.75831
06/23/2021 07:30:14 - INFO - __main__ -    Train | Loss: 0.73396
06/23/2021 07:37:56 - INFO - __main__ -    Train | Loss: 0.71174
06/23/2021 07:45:36 - INFO - __main__ -    Train | Loss: 0.69050
06/23/2021 07:53:16 - INFO - __main__ -    Train | Loss: 0.67089
06/23/2021 08:00:58 - INFO - __main__ -    Train | Loss: 0.65254
06/23/2021 08:08:38 - INFO - __main__ -    Train | Loss: 0.63485
06/23/2021 08:16:21 - INFO - __main__ -    Train | Loss: 0.61872
06/23/2021 08:24:04 - INFO - __main__ -    Train | Loss: 0.60350
06/23/2021 08:31:47 - INFO - __main__ -    Train | Loss: 0.58884
06/23/2021 08:39:29 - INFO - __main__ -    Train | Loss: 0.57484
06/23/2021 08:47:10 - INFO - __main__ -    Train | Loss: 0.56156
06/23/2021 08:54:52 - INFO - __main__ -    Train | Loss: 0.54939
06/23/2021 09:02:34 - INFO - __main__ -    Train | Loss: 0.53752
06/23/2021 09:10:16 - INFO - __main__ -    Train | Loss: 0.52636
06/23/2021 09:17:58 - INFO - __main__ -    Train | Loss: 0.51542
06/23/2021 09:25:41 - INFO - __main__ -    Train | Loss: 0.50531
06/23/2021 09:33:24 - INFO - __main__ -    Train | Loss: 0.49531
06/23/2021 09:41:07 - INFO - __main__ -    Train | Loss: 0.48571
06/23/2021 09:48:47 - INFO - __main__ -    Train | Loss: 0.47654
06/23/2021 09:56:25 - INFO - __main__ -    Train | Loss: 0.46786
06/23/2021 10:04:05 - INFO - __main__ -    Train | Loss: 0.45964
06/23/2021 10:04:22 - INFO - __main__ -    Train | Loss: 0.45932
06/23/2021 10:35:54 - INFO - pred_utils -    Post-processing 25094 example predictions split into 26864 features.
06/23/2021 10:37:37 - INFO - __main__ -    Valid | MAA: 0.97689, JAA: 0.81555, MEM: 0.95075, JEM: 0.81881, MGA: 0.96047, JGA: 0.69748
Configuration saved in ./saved/0623-0318/config.json
Model weights saved in ./saved/0623-0318/pytorch_model.bin
06/23/2021 10:37:42 - INFO - __main__ -    Saving config and model to ./saved/0623-0318...
06/23/2021 10:37:42 - INFO - __main__ -    
Epoch 02 / 03
06/23/2021 10:45:23 - INFO - __main__ -    Train | Loss: 0.05767
06/23/2021 10:53:05 - INFO - __main__ -    Train | Loss: 0.05661
06/23/2021 11:00:46 - INFO - __main__ -    Train | Loss: 0.05786
06/23/2021 11:08:26 - INFO - __main__ -    Train | Loss: 0.05892
06/23/2021 11:16:08 - INFO - __main__ -    Train | Loss: 0.05908
06/23/2021 11:23:49 - INFO - __main__ -    Train | Loss: 0.05882
06/23/2021 11:31:30 - INFO - __main__ -    Train | Loss: 0.05883
06/23/2021 11:39:11 - INFO - __main__ -    Train | Loss: 0.06003
06/23/2021 11:46:52 - INFO - __main__ -    Train | Loss: 0.05903
06/23/2021 11:54:34 - INFO - __main__ -    Train | Loss: 0.05797
06/23/2021 12:02:14 - INFO - __main__ -    Train | Loss: 0.05789
06/23/2021 12:09:58 - INFO - __main__ -    Train | Loss: 0.05734
06/23/2021 12:17:41 - INFO - __main__ -    Train | Loss: 0.05732
06/23/2021 12:25:23 - INFO - __main__ -    Train | Loss: 0.05772
06/23/2021 12:33:04 - INFO - __main__ -    Train | Loss: 0.05741
06/23/2021 12:40:45 - INFO - __main__ -    Train | Loss: 0.05706
06/23/2021 12:48:26 - INFO - __main__ -    Train | Loss: 0.05716
06/23/2021 12:56:08 - INFO - __main__ -    Train | Loss: 0.05699
06/23/2021 13:03:50 - INFO - __main__ -    Train | Loss: 0.05660
06/23/2021 13:11:31 - INFO - __main__ -    Train | Loss: 0.05642
06/23/2021 13:19:12 - INFO - __main__ -    Train | Loss: 0.05605
06/23/2021 13:26:50 - INFO - __main__ -    Train | Loss: 0.05624
06/23/2021 13:34:33 - INFO - __main__ -    Train | Loss: 0.05591
06/23/2021 13:42:15 - INFO - __main__ -    Train | Loss: 0.05593
06/23/2021 13:49:56 - INFO - __main__ -    Train | Loss: 0.05613
06/23/2021 14:21:30 - INFO - pred_utils -    Post-processing 25094 example predictions split into 26864 features.
06/23/2021 14:23:15 - INFO - __main__ -    Valid | MAA: 0.98031, JAA: 0.84813, MEM: 0.95552, JEM: 0.83998, MGA: 0.96557, JGA: 0.74552
Configuration saved in ./saved/0623-0318/config.json
Model weights saved in ./saved/0623-0318/pytorch_model.bin
06/23/2021 14:23:20 - INFO - __main__ -    Saving config and model to ./saved/0623-0318...
06/23/2021 14:31:03 - INFO - __main__ -    Train | Loss: 0.05590
06/23/2021 14:38:47 - INFO - __main__ -    Train | Loss: 0.05600
06/23/2021 14:46:31 - INFO - __main__ -    Train | Loss: 0.05581
06/23/2021 14:54:15 - INFO - __main__ -    Train | Loss: 0.05563
06/23/2021 15:01:57 - INFO - __main__ -    Train | Loss: 0.05518
06/23/2021 15:09:39 - INFO - __main__ -    Train | Loss: 0.05530
06/23/2021 15:17:21 - INFO - __main__ -    Train | Loss: 0.05524
06/23/2021 15:25:03 - INFO - __main__ -    Train | Loss: 0.05496
06/23/2021 15:32:45 - INFO - __main__ -    Train | Loss: 0.05486
06/23/2021 15:40:28 - INFO - __main__ -    Train | Loss: 0.05472
06/23/2021 15:48:11 - INFO - __main__ -    Train | Loss: 0.05469
06/23/2021 15:55:53 - INFO - __main__ -    Train | Loss: 0.05471
06/23/2021 16:03:37 - INFO - __main__ -    Train | Loss: 0.05458
06/23/2021 16:11:20 - INFO - __main__ -    Train | Loss: 0.05444
06/23/2021 16:19:00 - INFO - __main__ -    Train | Loss: 0.05421
06/23/2021 16:26:42 - INFO - __main__ -    Train | Loss: 0.05415
06/23/2021 16:34:28 - INFO - __main__ -    Train | Loss: 0.05403
06/23/2021 16:42:11 - INFO - __main__ -    Train | Loss: 0.05393
06/23/2021 16:49:54 - INFO - __main__ -    Train | Loss: 0.05365
06/23/2021 16:57:37 - INFO - __main__ -    Train | Loss: 0.05338
06/23/2021 17:05:19 - INFO - __main__ -    Train | Loss: 0.05337
06/23/2021 17:13:01 - INFO - __main__ -    Train | Loss: 0.05319
06/23/2021 17:13:18 - INFO - __main__ -    Train | Loss: 0.05320
06/23/2021 17:44:51 - INFO - pred_utils -    Post-processing 25094 example predictions split into 26864 features.
06/23/2021 17:46:37 - INFO - __main__ -    Valid | MAA: 0.98123, JAA: 0.85179, MEM: 0.96358, JEM: 0.86238, MGA: 0.96824, JGA: 0.75896
Configuration saved in ./saved/0623-0318/config.json
Model weights saved in ./saved/0623-0318/pytorch_model.bin
06/23/2021 17:46:42 - INFO - __main__ -    Saving config and model to ./saved/0623-0318...
06/23/2021 17:46:42 - INFO - __main__ -    
Epoch 03 / 03
06/23/2021 17:54:29 - INFO - __main__ -    Train | Loss: 0.03026
06/23/2021 18:02:11 - INFO - __main__ -    Train | Loss: 0.03014
06/23/2021 18:09:55 - INFO - __main__ -    Train | Loss: 0.03054
06/23/2021 18:17:38 - INFO - __main__ -    Train | Loss: 0.03122
06/23/2021 18:25:20 - INFO - __main__ -    Train | Loss: 0.03172
06/23/2021 18:33:01 - INFO - __main__ -    Train | Loss: 0.03194
06/23/2021 18:40:41 - INFO - __main__ -    Train | Loss: 0.03157
06/23/2021 18:48:21 - INFO - __main__ -    Train | Loss: 0.03150
06/23/2021 18:56:02 - INFO - __main__ -    Train | Loss: 0.03112
06/23/2021 19:03:42 - INFO - __main__ -    Train | Loss: 0.03045
06/23/2021 19:11:22 - INFO - __main__ -    Train | Loss: 0.03012
06/23/2021 19:19:01 - INFO - __main__ -    Train | Loss: 0.02981
06/23/2021 19:26:40 - INFO - __main__ -    Train | Loss: 0.02951
06/23/2021 19:34:17 - INFO - __main__ -    Train | Loss: 0.02998
06/23/2021 19:41:56 - INFO - __main__ -    Train | Loss: 0.02976
06/23/2021 19:49:37 - INFO - __main__ -    Train | Loss: 0.02996
06/23/2021 19:57:16 - INFO - __main__ -    Train | Loss: 0.03022
06/23/2021 20:04:57 - INFO - __main__ -    Train | Loss: 0.03017
06/23/2021 20:12:37 - INFO - __main__ -    Train | Loss: 0.03019
06/23/2021 20:20:16 - INFO - __main__ -    Train | Loss: 0.03017
06/23/2021 20:27:55 - INFO - __main__ -    Train | Loss: 0.03011
06/23/2021 20:35:35 - INFO - __main__ -    Train | Loss: 0.03019
06/23/2021 20:43:16 - INFO - __main__ -    Train | Loss: 0.03055
06/23/2021 20:50:57 - INFO - __main__ -    Train | Loss: 0.03052
06/23/2021 20:58:37 - INFO - __main__ -    Train | Loss: 0.03044
06/23/2021 21:30:09 - INFO - pred_utils -    Post-processing 25094 example predictions split into 26864 features.
06/23/2021 21:31:54 - INFO - __main__ -    Valid | MAA: 0.98219, JAA: 0.85993, MEM: 0.96489, JEM: 0.87052, MGA: 0.97047, JGA: 0.77769
Configuration saved in ./saved/0623-0318/config.json
Model weights saved in ./saved/0623-0318/pytorch_model.bin
06/23/2021 21:31:59 - INFO - __main__ -    Saving config and model to ./saved/0623-0318...
06/23/2021 21:39:40 - INFO - __main__ -    Train | Loss: 0.03029
06/23/2021 21:47:21 - INFO - __main__ -    Train | Loss: 0.03026
06/23/2021 21:55:00 - INFO - __main__ -    Train | Loss: 0.03017
06/23/2021 22:02:40 - INFO - __main__ -    Train | Loss: 0.03002
06/23/2021 22:10:20 - INFO - __main__ -    Train | Loss: 0.02997
06/23/2021 22:17:59 - INFO - __main__ -    Train | Loss: 0.02982
06/23/2021 22:25:37 - INFO - __main__ -    Train | Loss: 0.02970
06/23/2021 22:33:15 - INFO - __main__ -    Train | Loss: 0.02956
06/23/2021 22:40:52 - INFO - __main__ -    Train | Loss: 0.02945
06/23/2021 22:48:29 - INFO - __main__ -    Train | Loss: 0.02958
06/23/2021 22:56:08 - INFO - __main__ -    Train | Loss: 0.02964
06/23/2021 23:03:46 - INFO - __main__ -    Train | Loss: 0.02951
06/23/2021 23:11:24 - INFO - __main__ -    Train | Loss: 0.02944
06/23/2021 23:19:01 - INFO - __main__ -    Train | Loss: 0.02933
06/23/2021 23:26:39 - INFO - __main__ -    Train | Loss: 0.02934
06/23/2021 23:34:19 - INFO - __main__ -    Train | Loss: 0.02917
06/23/2021 23:41:58 - INFO - __main__ -    Train | Loss: 0.02921
06/23/2021 23:49:36 - INFO - __main__ -    Train | Loss: 0.02917
06/23/2021 23:57:14 - INFO - __main__ -    Train | Loss: 0.02906
06/24/2021 00:04:54 - INFO - __main__ -    Train | Loss: 0.02896
06/24/2021 00:12:31 - INFO - __main__ -    Train | Loss: 0.02885
06/24/2021 00:20:10 - INFO - __main__ -    Train | Loss: 0.02882
06/24/2021 00:20:27 - INFO - __main__ -    Train | Loss: 0.02882
06/24/2021 00:51:51 - INFO - pred_utils -    Post-processing 25094 example predictions split into 26864 features.
06/24/2021 00:53:33 - INFO - __main__ -    Valid | MAA: 0.98239, JAA: 0.86319, MEM: 0.96517, JEM: 0.87215, MGA: 0.97111, JGA: 0.78176
Configuration saved in ./saved/0623-0318/config.json
Model weights saved in ./saved/0623-0318/pytorch_model.bin
06/24/2021 00:53:38 - INFO - __main__ -    Saving config and model to ./saved/0623-0318...
Configuration saved in ./saved/0623-0318/config.json
Model weights saved in ./saved/0623-0318/pytorch_model.bin
06/24/2021 00:53:45 - INFO - __main__ -    Saving config and model to ./saved/0623-0318...
